<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width">
    <title>Community Bonding - The Rootavish Files
    </title>
    <link rel="alternate" href="http://localhost:8080/feed.xml" type="application/rss+xml" title="Set up for and currently being used exclsively for doing weekly write ups as a GSoC student for ScrapingHub">
    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic|Anonymous+Pro:400,700,400italic,700italic|Merriweather:400,700,300">
    <link rel="stylesheet" href="/css/main.css">
  </head>
  <body class="article-detail">
    <header class="header">
      <div class="content-wrap">
        <h1>Community Bonding</h1>
        <p class="author">Written by <span class="author"><a href="mailto:rootavish@gmail.com">rootavish</a></span>
        </p>
      </div>
    </header>
    <div id="content">
      <div class="content-wrap">
        <article class="article">
          <section class="content"><p>Hey there, this is the first in the series of posts aimed at documenting my experience as a GSoC 2016 student for regular reporting to the org,
and for my own reference to have something to look back on in retrospect. For the first post, let me start with spouting off a little about myself,
and then I’ll talk about how the experience has been to&nbsp;date.</p>
<p><span class="more"></span>
I’m a(or rather was) a final year student of Computer Engineering at a college in New Delhi, and I’ve been a part of the GSoC program back in 2014,
where I worked for <a href="http://mate-desktop.org"><span class="caps">MATE</span> desktop</a>. For the last year or so, I’ve been dabbling in data science and machine learning, and came
to know of Scrapy when I used it for one such project early on to scrape opinions from an e-commerce site. Fast forward a year and casually browsing through
<span class="caps">PSF</span>’s list of GSoC organizations I got to know that these guys were also participating and decided to give it a shot. Given how hectic the schedule was for me back
in February, I would be lying if I said that the reason for my selection was me being some sort of a big-shot programmer who came in all guns blazing. I approached
this as passively as one possibly could, it was due to the efforts of the ScrapingHub suborg admin Paul who showed interst in my proposal, gave me an interview
and put me to work on a bug which also made me familiar with the actual inner workings of Scrapy that I was able to gain footing on the&nbsp;project.  </p>
<p>My project for this summer is going to deal with re-factoring the Scrapy signaling <span class="caps">API</span>, in an effort to move away from the PyDispatcher library which would greatly
enchance the performance of signals. Django moved away from PyDispatcher in 2001, and they reportedly observed an increase of upto 90% in efficiency. I intend to build
off their work and assume we would see similar results in&nbsp;Scrapy.  </p>
<p>The Scrapy community are a really active lot, and my “community bonding” started just a couple days into the announcement of me being selected for the project, which is good
because I’ve had exams for the past couple of weeks or so and was <span class="caps">AFK</span> for a major part of them(of course informing my mentors about the same first). I had a video chat with my
mentor Jakob where we figured out how reporting etc. would work for the summer, our next chat is scheduled for the 24^th, 25^th where we shall discuss how the actual implementation
of the project will be and what plans I have for the same. I also finalised the work on a bug I was working on and had submitted in the form of a patch as a part of my proposal.
The Scrapy community is really responsive, and I’m honored to be a part of it and to be working with all the people here. I hope my work is up to their standards at the end of this.
Since there is not much Technical content to write about at this point, with the coding period having not yet started so we’ll keep this one short, I’ll bore you with the
technical details in the next one. Thanks for reading, the next post will go up on Sunday the 28<span class="ord">th</span>. Signing&nbsp;off.</p>
</section>
        </article>
      </div>
    </div>
    <footer>
      <div class="content-wrap">
        <div class="nav"><a href="/">&laquo; Full blog</a></div>
        <section class="about"><p>Hi, I’m Avishkar Gupta, a full time college student soon to be professional developer 
as my four years of college come to an end this year. You can check out the work that is 
documented here over on <a href="https://github.com/rootavish/">Github</a>. 
I’ve indulged quite a bit into the machine learning and data science side of things
and wish to go back to uni sometime to further my research into the area.</p>

        </section>
        <section class="copy">
          <p>&copy; 2016 Avishkar Gupta (rootavish) &mdash; powered by&nbsp;<a href="https://github.com/jnordberg/wintersmith">Wintersmith</a>
          </p>
        </section>
      </div>
    </footer>
  </body>
</html>